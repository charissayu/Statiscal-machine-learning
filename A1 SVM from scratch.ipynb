{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math as m\n",
    "from sklearn.metrics import accuracy_score\n",
    "from cvxopt import matrix, solvers\n",
    "from numpy import array\n",
    "\n",
    "import cvxopt\n",
    "\n",
    "#import cvxopt.solvers\n",
    "#from cvxopt import matrix as cvxopt_matrix\n",
    "#from cvxopt import solvers as cvxopt_solvers\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv', header=None)\n",
    "test_data = pd.read_csv('test.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6800, 200) (1700, 200) (6800,) (1700,)\n"
     ]
    }
   ],
   "source": [
    "data_train = train_data.iloc[:6800,1:]\n",
    "data_train = data_train.to_numpy()\n",
    "\n",
    "data_val = train_data.iloc[6800:,1:]\n",
    "data_val = data_val.to_numpy()\n",
    "\n",
    "label_train = train_data.iloc[:6800,0]\n",
    "label_train = label_train.to_numpy()\n",
    "\n",
    "label_val = train_data.iloc[6800:,0]\n",
    "label_val = label_val.to_numpy()\n",
    "\n",
    "print(data_train.shape, data_val.shape, label_train.shape, label_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = test_data.iloc[:,1:]\n",
    "data_test = data_test.to_numpy()\n",
    "\n",
    "label_test = test_data.iloc[:,0]\n",
    "label_test = label_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change label 0 to -1\n",
    "label_train = np.where(label_train==0, -1, label_train) \n",
    "label_val = np.where(label_val==0, -1, label_val) \n",
    "label_test = np.where(label_test==0, -1, label_test) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train_dual(X, y, regularisation_para_C):\n",
    "    m,n = data_train.shape\n",
    "    \n",
    "    y = y.reshape(-1,1) * 1.\n",
    "    \n",
    "    y_diag = np.asarray(np.diag(np.ones(y.shape[0]))*y) \n",
    "    X_dd = np.dot(y_diag, X)\n",
    "    X_dd.shape\n",
    "    \n",
    "    H = np.dot(X_dd , X_dd.T) * 1.\n",
    "    P = matrix(H)\n",
    "    q = matrix(-np.ones((m, 1)))\n",
    "    g1 = np.eye(m)*-1\n",
    "    g2 = np.eye(m)\n",
    "    g3 = np.vstack((g1,g2))\n",
    "    G = matrix(g3)\n",
    "    \n",
    "    h1 = np.zeros(m)\n",
    "    h2 = np.ones(m)\n",
    "    h = np.hstack((h1, h2 * regularisation_para_C/m))\n",
    "    h = matrix(h)\n",
    "    \n",
    "    A = matrix(y.reshape(1, -1))\n",
    "    b = matrix(np.zeros(1))\n",
    "    sol = solvers.qp(P, q, G, h, A, b)\n",
    "    alphas = np.array(sol['x'])\n",
    "    \n",
    "    w1 = (y * alphas).T @ X\n",
    "    w = w1.reshape(-1,1)\n",
    "\n",
    "    S = (alphas > 1e-4).flatten()\n",
    "    b = y[S] - np.dot(X[S], w)\n",
    "    b = b.mean()\n",
    "    svm_model_d = np.vstack((w,b))\n",
    "    return svm_model_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_predict_dual(data_test, label_test, svm_model_d):    \n",
    "    m,n = data_train.shape\n",
    "    y_pred = np.dot(svm_model_d[:n].T, data_test.T)+svm_model_d[-1]\n",
    "    y_pred = np.sign(y_pred)\n",
    "    y_pred = y_pred.reshape(label_test.shape)\n",
    "    score = accuracy_score(label_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.6642e+02 -2.3866e+00  7e+04  3e+02  6e-13\n",
      " 1: -6.8933e+00 -2.3864e+00  7e+02  3e+00  6e-13\n",
      " 2: -2.9663e-01 -2.3650e+00  1e+01  4e-02  1e-14\n",
      " 3: -1.7203e-01 -1.6592e+00  2e+00  4e-03  2e-15\n",
      " 4: -1.6674e-01 -3.7098e-01  2e-01  2e-04  4e-15\n",
      " 5: -2.1463e-01 -2.7816e-01  7e-02  4e-05  2e-15\n",
      " 6: -2.2943e-01 -2.5920e-01  3e-02  2e-05  2e-15\n",
      " 7: -2.3590e-01 -2.5074e-01  2e-02  7e-06  2e-15\n",
      " 8: -2.3976e-01 -2.4571e-01  6e-03  2e-06  2e-15\n",
      " 9: -2.4152e-01 -2.4347e-01  2e-03  6e-07  2e-15\n",
      "10: -2.4216e-01 -2.4268e-01  5e-04  9e-08  2e-15\n",
      "11: -2.4239e-01 -2.4243e-01  4e-05  3e-09  2e-15\n",
      "12: -2.4241e-01 -2.4241e-01  1e-06  8e-11  2e-15\n",
      "13: -2.4241e-01 -2.4241e-01  2e-08  1e-12  2e-15\n",
      "Optimal solution found.\n",
      "1 0.9752941176470589\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.6682e+02 -1.1742e+01  7e+04  3e+02  6e-13\n",
      " 1: -7.6408e+00 -1.1736e+01  7e+02  3e+00  6e-13\n",
      " 2: -1.0220e+00 -1.1176e+01  4e+01  1e-01  3e-14\n",
      " 3: -5.8089e-01 -6.0065e+00  8e+00  1e-02  5e-15\n",
      " 4: -4.4906e-01 -1.3218e+00  1e+00  1e-03  9e-15\n",
      " 5: -5.7269e-01 -8.8187e-01  3e-01  4e-04  4e-15\n",
      " 6: -6.0797e-01 -8.0156e-01  2e-01  2e-04  2e-15\n",
      " 7: -6.3804e-01 -7.3820e-01  1e-01  8e-05  2e-15\n",
      " 8: -6.5256e-01 -7.0975e-01  6e-02  4e-05  2e-15\n",
      " 9: -6.6308e-01 -6.9081e-01  3e-02  2e-05  2e-15\n",
      "10: -6.6873e-01 -6.8097e-01  1e-02  5e-06  2e-15\n",
      "11: -6.7254e-01 -6.7555e-01  3e-03  8e-07  3e-15\n",
      "12: -6.7350e-01 -6.7426e-01  8e-04  1e-07  3e-15\n",
      "13: -6.7378e-01 -6.7392e-01  1e-04  2e-08  3e-15\n",
      "14: -6.7384e-01 -6.7385e-01  4e-06  4e-10  4e-15\n",
      "15: -6.7384e-01 -6.7384e-01  7e-08  7e-12  4e-15\n",
      "Optimal solution found.\n",
      "5 0.9747058823529412\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.6731e+02 -2.3438e+01  7e+04  3e+02  7e-13\n",
      " 1: -8.5954e+00 -2.3413e+01  7e+02  3e+00  6e-13\n",
      " 2: -1.9031e+00 -2.1365e+01  7e+01  2e-01  4e-14\n",
      " 3: -1.0988e+00 -1.0456e+01  1e+01  2e-02  7e-15\n",
      " 4: -7.8342e-01 -2.4697e+00  2e+00  3e-03  1e-14\n",
      " 5: -9.3191e-01 -1.5689e+00  7e-01  9e-04  6e-15\n",
      " 6: -9.7760e-01 -1.4105e+00  5e-01  5e-04  4e-15\n",
      " 7: -1.0229e+00 -1.2698e+00  3e-01  2e-04  3e-15\n",
      " 8: -1.0518e+00 -1.1920e+00  1e-01  1e-04  2e-15\n",
      " 9: -1.0765e+00 -1.1407e+00  7e-02  3e-05  3e-15\n",
      "10: -1.0915e+00 -1.1134e+00  2e-02  6e-06  3e-15\n",
      "11: -1.0982e+00 -1.1037e+00  6e-03  1e-06  4e-15\n",
      "12: -1.1001e+00 -1.1012e+00  1e-03  1e-07  4e-15\n",
      "13: -1.1005e+00 -1.1007e+00  2e-04  1e-08  4e-15\n",
      "14: -1.1006e+00 -1.1006e+00  6e-06  5e-10  5e-15\n",
      "15: -1.1006e+00 -1.1006e+00  2e-07  1e-11  5e-15\n",
      "Optimal solution found.\n",
      "10 0.9770588235294118\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.6780e+02 -3.5137e+01  7e+04  3e+02  6e-13\n",
      " 1: -9.5489e+00 -3.5079e+01  8e+02  3e+00  7e-13\n",
      " 2: -2.7408e+00 -3.0876e+01  9e+01  3e-01  6e-14\n",
      " 3: -1.6108e+00 -1.4281e+01  2e+01  3e-02  9e-15\n",
      " 4: -1.1348e+00 -3.6917e+00  3e+00  5e-03  1e-14\n",
      " 5: -1.2708e+00 -2.2382e+00  1e+00  2e-03  6e-15\n",
      " 6: -1.3438e+00 -1.8812e+00  6e-01  7e-04  4e-15\n",
      " 7: -1.3971e+00 -1.6894e+00  3e-01  3e-04  3e-15\n",
      " 8: -1.4316e+00 -1.5810e+00  2e-01  7e-05  3e-15\n",
      " 9: -1.4647e+00 -1.5215e+00  6e-02  2e-05  4e-15\n",
      "10: -1.4778e+00 -1.5001e+00  2e-02  3e-06  4e-15\n",
      "11: -1.4844e+00 -1.4909e+00  7e-03  2e-16  4e-15\n",
      "12: -1.4870e+00 -1.4881e+00  1e-03  2e-16  5e-15\n",
      "13: -1.4875e+00 -1.4876e+00  1e-04  1e-16  5e-15\n",
      "14: -1.4875e+00 -1.4875e+00  2e-06  2e-16  6e-15\n",
      "15: -1.4875e+00 -1.4875e+00  3e-08  3e-16  6e-15\n",
      "Optimal solution found.\n",
      "15 0.9741176470588235\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.6829e+02 -4.6838e+01  7e+04  3e+02  7e-13\n",
      " 1: -1.0501e+01 -4.6735e+01  8e+02  3e+00  7e-13\n",
      " 2: -3.5420e+00 -3.9882e+01  1e+02  3e-01  7e-14\n",
      " 3: -2.1118e+00 -1.7643e+01  2e+01  4e-02  1e-14\n",
      " 4: -1.4978e+00 -4.9569e+00  5e+00  8e-03  1e-14\n",
      " 5: -1.6029e+00 -2.9039e+00  2e+00  2e-03  7e-15\n",
      " 6: -1.6790e+00 -2.3906e+00  8e-01  1e-03  5e-15\n",
      " 7: -1.7453e+00 -2.1216e+00  4e-01  4e-04  4e-15\n",
      " 8: -1.7916e+00 -1.9664e+00  2e-01  1e-04  4e-15\n",
      " 9: -1.8246e+00 -1.8932e+00  7e-02  1e-05  4e-15\n",
      "10: -1.8448e+00 -1.8660e+00  2e-02  2e-06  5e-15\n",
      "11: -1.8513e+00 -1.8577e+00  6e-03  4e-07  5e-15\n",
      "12: -1.8538e+00 -1.8548e+00  1e-03  5e-08  5e-15\n",
      "13: -1.8542e+00 -1.8543e+00  1e-04  4e-09  6e-15\n",
      "14: -1.8542e+00 -1.8542e+00  2e-06  5e-11  6e-15\n",
      "Optimal solution found.\n",
      "20 0.9735294117647059\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.7122e+02 -1.1710e+02  7e+04  3e+02  7e-13\n",
      " 1: -1.6195e+01 -1.1645e+02  1e+03  4e+00  7e-13\n",
      " 2: -7.8272e+00 -8.7580e+01  2e+02  5e-01  9e-14\n",
      " 3: -4.8416e+00 -3.1893e+01  4e+01  8e-02  2e-14\n",
      " 4: -3.6084e+00 -1.0773e+01  1e+01  2e-02  1e-14\n",
      " 5: -3.5426e+00 -6.1215e+00  3e+00  6e-03  9e-15\n",
      " 6: -3.6088e+00 -4.8724e+00  1e+00  2e-03  8e-15\n",
      " 7: -3.7298e+00 -4.3129e+00  7e-01  6e-04  7e-15\n",
      " 8: -3.8057e+00 -4.0655e+00  3e-01  2e-04  7e-15\n",
      " 9: -3.8386e+00 -3.9797e+00  1e-01  4e-05  7e-15\n",
      "10: -3.8713e+00 -3.9309e+00  6e-02  8e-06  8e-15\n",
      "11: -3.8888e+00 -3.9082e+00  2e-02  2e-06  8e-15\n",
      "12: -3.8962e+00 -3.8990e+00  3e-03  1e-16  1e-14\n",
      "13: -3.8975e+00 -3.8976e+00  1e-04  4e-16  1e-14\n",
      "14: -3.8975e+00 -3.8976e+00  7e-06  1e-16  1e-14\n",
      "15: -3.8975e+00 -3.8975e+00  1e-07  1e-16  1e-14\n",
      "Optimal solution found.\n",
      "50 0.9747058823529412\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.7367e+02 -1.7572e+02  7e+04  3e+02  6e-13\n",
      " 1: -2.0912e+01 -1.7427e+02  1e+03  4e+00  6e-13\n",
      " 2: -1.0994e+01 -1.2238e+02  2e+02  6e-01  9e-14\n",
      " 3: -6.8951e+00 -4.1818e+01  6e+01  1e-01  2e-14\n",
      " 4: -5.3081e+00 -1.5191e+01  1e+01  3e-02  1e-14\n",
      " 5: -5.0187e+00 -8.9329e+00  5e+00  8e-03  1e-14\n",
      " 6: -5.1438e+00 -6.7703e+00  2e+00  2e-03  1e-14\n",
      " 7: -5.2769e+00 -6.1053e+00  9e-01  7e-04  1e-14\n",
      " 8: -5.3956e+00 -5.7303e+00  4e-01  1e-04  1e-14\n",
      " 9: -5.4499e+00 -5.6177e+00  2e-01  3e-05  1e-14\n",
      "10: -5.4866e+00 -5.5641e+00  8e-02  8e-06  1e-14\n",
      "11: -5.5114e+00 -5.5326e+00  2e-02  8e-07  1e-14\n",
      "12: -5.5197e+00 -5.5231e+00  3e-03  2e-16  1e-14\n",
      "13: -5.5212e+00 -5.5214e+00  2e-04  8e-16  1e-14\n",
      "14: -5.5213e+00 -5.5213e+00  4e-06  8e-16  1e-14\n",
      "Optimal solution found.\n",
      "75 0.9729411764705882\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.7612e+02 -2.3440e+02  7e+04  2e+02  7e-13\n",
      " 1: -2.5604e+01 -2.3183e+02  1e+03  4e+00  7e-13\n",
      " 2: -1.4056e+01 -1.5495e+02  3e+02  5e-01  1e-13\n",
      " 3: -8.9209e+00 -5.2523e+01  7e+01  1e-01  3e-14\n",
      " 4: -7.0393e+00 -2.0928e+01  2e+01  3e-02  1e-14\n",
      " 5: -6.5401e+00 -1.2874e+01  9e+00  1e-02  1e-14\n",
      " 6: -6.6385e+00 -9.5866e+00  4e+00  4e-03  1e-14\n",
      " 7: -6.8142e+00 -7.9569e+00  1e+00  1e-03  1e-14\n",
      " 8: -6.9321e+00 -7.5000e+00  6e-01  4e-04  1e-14\n",
      " 9: -7.0082e+00 -7.2944e+00  3e-01  1e-04  1e-14\n",
      "10: -7.0751e+00 -7.1739e+00  1e-01  3e-05  1e-14\n",
      "11: -7.0998e+00 -7.1319e+00  3e-02  2e-06  2e-14\n",
      "12: -7.1104e+00 -7.1196e+00  9e-03  3e-07  2e-14\n",
      "13: -7.1136e+00 -7.1159e+00  2e-03  7e-08  2e-14\n",
      "14: -7.1145e+00 -7.1149e+00  3e-04  4e-09  2e-14\n",
      "15: -7.1147e+00 -7.1147e+00  1e-05  1e-10  2e-14\n",
      "16: -7.1147e+00 -7.1147e+00  1e-07  1e-12  2e-14\n",
      "Optimal solution found.\n",
      "100 0.9747058823529412\n"
     ]
    }
   ],
   "source": [
    "C_param = [1, 5, 10, 15, 20, 50, 75, 100]\n",
    "\n",
    "for i in C_param:\n",
    "    svm_model_d = svm_train_dual(data_train , label_train , i)\n",
    "    test_accuracy_d = svm_predict_dual(data_val , label_val , svm_model_d)\n",
    "    print(i, test_accuracy_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.6731e+02 -2.3438e+01  7e+04  3e+02  7e-13\n",
      " 1: -8.5954e+00 -2.3413e+01  7e+02  3e+00  6e-13\n",
      " 2: -1.9031e+00 -2.1365e+01  7e+01  2e-01  4e-14\n",
      " 3: -1.0988e+00 -1.0456e+01  1e+01  2e-02  7e-15\n",
      " 4: -7.8342e-01 -2.4697e+00  2e+00  3e-03  1e-14\n",
      " 5: -9.3191e-01 -1.5689e+00  7e-01  9e-04  6e-15\n",
      " 6: -9.7760e-01 -1.4105e+00  5e-01  5e-04  4e-15\n",
      " 7: -1.0229e+00 -1.2698e+00  3e-01  2e-04  3e-15\n",
      " 8: -1.0518e+00 -1.1920e+00  1e-01  1e-04  2e-15\n",
      " 9: -1.0765e+00 -1.1407e+00  7e-02  3e-05  3e-15\n",
      "10: -1.0915e+00 -1.1134e+00  2e-02  6e-06  3e-15\n",
      "11: -1.0982e+00 -1.1037e+00  6e-03  1e-06  4e-15\n",
      "12: -1.1001e+00 -1.1012e+00  1e-03  1e-07  4e-15\n",
      "13: -1.1005e+00 -1.1007e+00  2e-04  1e-08  4e-15\n",
      "14: -1.1006e+00 -1.1006e+00  6e-06  5e-10  5e-15\n",
      "15: -1.1006e+00 -1.1006e+00  2e-07  1e-11  5e-15\n",
      "Optimal solution found.\n",
      "train accuracy is 0.9760294117647059\n",
      "validation accuracy is 0.9770588235294118\n",
      "test accuracy is 0.972\n"
     ]
    }
   ],
   "source": [
    "#predict with best performing hyperparameter C 10\n",
    "\n",
    "svm_model_d = svm_train_dual(data_train , label_train , 10)\n",
    "\n",
    "test_accuracy_d_train = svm_predict_dual(data_train , label_train , svm_model_d)\n",
    "print('train accuracy is', test_accuracy_d_train)\n",
    "\n",
    "test_accuracy_d_val = svm_predict_dual(data_val , label_val , svm_model_d)\n",
    "print('validation accuracy is', test_accuracy_d_val)\n",
    "\n",
    "test_accuracy_d_test = svm_predict_dual(data_test , label_test , svm_model_d)\n",
    "print('test accuracy is', test_accuracy_d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting weights and bias for dual model\n",
    "w = svm_model_d[:data_train.shape[1]]\n",
    "b = svm_model_d[-1]\n",
    "dual_w_series = pd.Series(w.flatten())\n",
    "dual_b_series = pd.Series(b)\n",
    "dual_series = pd.concat((dual_w_series, dual_b_series), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primal soft margin\n",
    "\n",
    "def svm_train_primal(X,y,regularisation_para_C):\n",
    "    m,n = X.shape\n",
    "    Pw = np.asarray(np.diag(np.ones(n))) \n",
    "    Ps = np.zeros([n, m]) \n",
    "    Pb = np.zeros([1, n]) \n",
    "    \n",
    "    P1 = np.zeros([m, m])\n",
    "    P2 = np.zeros([m, 1])\n",
    "    P3 = np.zeros([1, m])\n",
    "    P4 = np.zeros([1, 1]) \n",
    "    \n",
    "    Pup = np.concatenate((Pw, Ps, Pb.T),axis = 1) \n",
    "    Pmid = np.concatenate((Ps.T, P1, P2), axis=1)\n",
    "    Pdown = np.concatenate((Pb,P3, P4),axis = 1)\n",
    "    P = cvxopt.matrix(np.concatenate((Pup, Pmid, Pdown), axis = 0))\n",
    "    \n",
    "    q = np.concatenate((Pb, np.matrix(np.ones([m])*regularisation_para_C/m), P4), axis=1)\n",
    "    q = cvxopt.matrix((q.T))\n",
    "    \n",
    "    g1 = np.dot(np.diag(y),X)*-1\n",
    "    g2 = np.asarray(np.diag(np.ones([m])*-1))\n",
    "    g3 = np.matrix(y)*-1\n",
    "    g3 = g3.T\n",
    "    g4 = np.zeros([m, n+1])\n",
    "    g5 = np.asarray(np.diag(np.ones([m])*-1))\n",
    "\n",
    "    G1 = np.concatenate((g1,g2,g3), axis = 1)\n",
    "    G2 = np.concatenate((g4,g5), axis = 1)\n",
    "\n",
    "    G = np.vstack((G1,G2))\n",
    "    G = cvxopt.matrix(G) \n",
    "    \n",
    "    h1 = np.ones(m)*-1\n",
    "    h2 = np.zeros(m)\n",
    "    h = cvxopt.matrix(np.hstack((h1,h2)))             \n",
    "\n",
    "    svm_model = np.array(cvxopt.solvers.coneqp(P,q,G,h)['x']).flatten()\n",
    "    \n",
    "    return svm_model\n",
    "\n",
    "\n",
    "def svm_predict_primal(data_test, label_test, svm_model):\n",
    "    m,n = data_train.shape\n",
    "    w_prim = svm_model[:n]\n",
    "    b_prim = svm_model[-1]\n",
    "    \n",
    "    y_pred = np.dot(data_test, w_prim)+b_prim\n",
    "    y_pred = np.sign(y_pred)\n",
    "    \n",
    "    score = accuracy_score(label_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.4602e-01  6.6738e+02  7e+04  3e+00  4e+04\n",
      " 1:  2.3620e+00 -7.1394e+02  7e+02  3e-02  5e+02\n",
      " 2:  2.3653e+00 -1.3468e+01  2e+01  6e-04  9e+00\n",
      " 3:  1.8273e+00 -1.4054e+00  3e+00  9e-05  1e+00\n",
      " 4:  5.5964e-01  1.4574e-01  4e-01  3e-15  2e-15\n",
      " 5:  3.0464e-01  2.0083e-01  1e-01  2e-15  1e-15\n",
      " 6:  2.7023e-01  2.2348e-01  5e-02  1e-15  1e-15\n",
      " 7:  2.5392e-01  2.3426e-01  2e-02  1e-15  1e-15\n",
      " 8:  2.4647e-01  2.3940e-01  7e-03  1e-15  7e-16\n",
      " 9:  2.4351e-01  2.4153e-01  2e-03  1e-15  4e-15\n",
      "10:  2.4269e-01  2.4216e-01  5e-04  1e-15  2e-15\n",
      "11:  2.4243e-01  2.4239e-01  4e-05  1e-15  3e-15\n",
      "12:  2.4241e-01  2.4241e-01  1e-06  1e-15  8e-15\n",
      "13:  2.4241e-01  2.4241e-01  3e-08  1e-15  3e-14\n",
      "Optimal solution found.\n",
      "1 0.9741176470588235\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.3527e-01  6.7673e+02  7e+04  3e+00  4e+04\n",
      " 1:  1.1612e+01 -7.2266e+02  7e+02  3e-02  5e+02\n",
      " 2:  1.1199e+01 -3.6226e+01  5e+01  2e-03  3e+01\n",
      " 3:  6.9696e+00 -2.8811e+00  1e+01  2e-04  3e+00\n",
      " 4:  1.4516e+00  2.9328e-01  1e+00  1e-05  2e-01\n",
      " 5:  9.4547e-01  5.1894e-01  4e-01  4e-06  5e-02\n",
      " 6:  8.6969e-01  5.6243e-01  3e-01  2e-06  3e-02\n",
      " 7:  7.7455e-01  6.1417e-01  2e-01  1e-06  1e-02\n",
      " 8:  7.3267e-01  6.3782e-01  9e-02  6e-07  8e-03\n",
      " 9:  7.0452e-01  6.5385e-01  5e-02  2e-07  3e-03\n",
      "10:  6.8783e-01  6.6419e-01  2e-02  9e-08  1e-03\n",
      "11:  6.7860e-01  6.7030e-01  8e-03  2e-08  3e-04\n",
      "12:  6.7518e-01  6.7280e-01  2e-03  5e-09  7e-05\n",
      "13:  6.7415e-01  6.7360e-01  6e-04  9e-10  1e-05\n",
      "14:  6.7387e-01  6.7382e-01  5e-05  4e-11  6e-07\n",
      "15:  6.7385e-01  6.7384e-01  2e-06  1e-12  2e-08\n",
      "16:  6.7384e-01  6.7384e-01  3e-08  2e-14  3e-10\n",
      "Optimal solution found.\n",
      "5 0.9758823529411764\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.0159e+00  6.8843e+02  7e+04  3e+00  4e+04\n",
      " 1:  2.3159e+01 -7.4260e+02  8e+02  4e-02  5e+02\n",
      " 2:  2.1449e+01 -5.9102e+01  8e+01  3e-03  4e+01\n",
      " 3:  1.2255e+01 -4.8566e+00  2e+01  4e-04  5e+00\n",
      " 4:  2.8854e+00  2.7904e-01  3e+00  4e-05  5e-01\n",
      " 5:  1.6190e+00  8.2015e-01  8e-01  1e-05  1e-01\n",
      " 6:  1.4284e+00  9.2156e-01  5e-01  5e-06  8e-02\n",
      " 7:  1.2900e+00  9.9213e-01  3e-01  2e-06  3e-02\n",
      " 8:  1.2058e+00  1.0372e+00  2e-01  1e-06  2e-02\n",
      " 9:  1.1498e+00  1.0686e+00  8e-02  4e-07  6e-03\n",
      "10:  1.1165e+00  1.0889e+00  3e-02  7e-08  1e-03\n",
      "11:  1.1043e+00  1.0977e+00  7e-03  1e-08  2e-04\n",
      "12:  1.1013e+00  1.1000e+00  1e-03  2e-09  2e-05\n",
      "13:  1.1007e+00  1.1005e+00  2e-04  2e-10  3e-06\n",
      "14:  1.1006e+00  1.1006e+00  9e-06  9e-12  1e-07\n",
      "15:  1.1006e+00  1.1006e+00  2e-07  2e-13  3e-09\n",
      "Optimal solution found.\n",
      "10 0.9770588235294118\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.4898e+00  7.0012e+02  7e+04  3e+00  4e+04\n",
      " 1:  3.4687e+01 -7.6329e+02  8e+02  4e-02  5e+02\n",
      " 2:  3.1046e+01 -7.7603e+01  1e+02  4e-03  6e+01\n",
      " 3:  1.6696e+01 -6.2375e+00  2e+01  5e-04  7e+00\n",
      " 4:  4.2873e+00  2.1636e-01  4e+00  7e-05  1e+00\n",
      " 5:  2.3270e+00  1.0601e+00  1e+00  2e-05  3e-01\n",
      " 6:  1.9713e+00  1.2351e+00  7e-01  8e-06  1e-01\n",
      " 7:  1.7659e+00  1.3371e+00  4e-01  4e-06  6e-02\n",
      " 8:  1.6703e+00  1.3835e+00  3e-01  2e-06  3e-02\n",
      " 9:  1.5446e+00  1.4441e+00  1e-01  5e-08  7e-04\n",
      "10:  1.5113e+00  1.4686e+00  4e-02  1e-08  2e-04\n",
      "11:  1.4980e+00  1.4789e+00  2e-02  4e-09  6e-05\n",
      "12:  1.4900e+00  1.4853e+00  5e-03  2e-15  6e-14\n",
      "13:  1.4878e+00  1.4873e+00  6e-04  2e-15  1e-13\n",
      "14:  1.4876e+00  1.4875e+00  7e-05  2e-15  3e-13\n",
      "15:  1.4875e+00  1.4875e+00  1e-06  2e-15  3e-13\n",
      "Optimal solution found.\n",
      "15 0.9752941176470589\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.9572e+00  7.1182e+02  7e+04  3e+00  4e+04\n",
      " 1:  4.6198e+01 -7.8393e+02  8e+02  4e-02  5e+02\n",
      " 2:  4.0155e+01 -9.2982e+01  1e+02  5e-03  7e+01\n",
      " 3:  2.0602e+01 -7.5097e+00  3e+01  6e-04  9e+00\n",
      " 4:  5.5610e+00  1.6152e-01  5e+00  1e-04  1e+00\n",
      " 5:  2.9983e+00  1.2859e+00  2e+00  3e-05  4e-01\n",
      " 6:  2.5122e+00  1.5180e+00  1e+00  1e-05  2e-01\n",
      " 7:  2.1437e+00  1.6957e+00  4e-01  4e-06  6e-02\n",
      " 8:  1.9776e+00  1.7758e+00  2e-01  1e-06  1e-02\n",
      " 9:  1.9011e+00  1.8212e+00  8e-02  3e-07  4e-03\n",
      "10:  1.8668e+00  1.8441e+00  2e-02  3e-08  4e-04\n",
      "11:  1.8581e+00  1.8509e+00  7e-03  7e-09  9e-05\n",
      "12:  1.8548e+00  1.8537e+00  1e-03  7e-10  1e-05\n",
      "13:  1.8543e+00  1.8542e+00  1e-04  6e-11  8e-07\n",
      "14:  1.8542e+00  1.8542e+00  2e-06  7e-13  9e-09\n",
      "15:  1.8542e+00  1.8542e+00  2e-08  9e-15  1e-10\n",
      "Optimal solution found.\n",
      "20 0.9752941176470589\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.6219e+00  7.8203e+02  7e+04  3e+00  4e+04\n",
      " 1:  1.1488e+02 -9.1356e+02  1e+03  4e-02  6e+02\n",
      " 2:  8.9073e+01 -1.5240e+02  2e+02  9e-03  1e+02\n",
      " 3:  3.7822e+01 -1.2531e+01  5e+01  1e-03  2e+01\n",
      " 4:  1.2262e+01 -4.8862e-02  1e+01  3e-04  4e+00\n",
      " 5:  6.5095e+00  2.6077e+00  4e+00  8e-05  1e+00\n",
      " 6:  5.0669e+00  3.2943e+00  2e+00  3e-05  4e-01\n",
      " 7:  4.4620e+00  3.5942e+00  9e-01  1e-05  2e-01\n",
      " 8:  4.1203e+00  3.7549e+00  4e-01  2e-06  3e-02\n",
      " 9:  4.0043e+00  3.8229e+00  2e-01  8e-07  1e-02\n",
      "10:  3.9458e+00  3.8574e+00  9e-02  1e-07  1e-03\n",
      "11:  3.9138e+00  3.8837e+00  3e-02  2e-08  3e-04\n",
      "12:  3.9022e+00  3.8933e+00  9e-03  2e-09  3e-05\n",
      "13:  3.8980e+00  3.8971e+00  9e-04  7e-11  9e-07\n",
      "14:  3.8976e+00  3.8975e+00  1e-04  7e-12  1e-07\n",
      "15:  3.8976e+00  3.8975e+00  6e-06  4e-13  6e-09\n",
      "16:  3.8975e+00  3.8975e+00  1e-07  8e-15  1e-10\n",
      "Optimal solution found.\n",
      "50 0.9723529411764706\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  6.6601e+00  8.4060e+02  7e+04  3e+00  4e+04\n",
      " 1:  1.7157e+02 -1.0368e+03  1e+03  5e-02  7e+02\n",
      " 2:  1.2617e+02 -1.8475e+02  3e+02  1e-02  2e+02\n",
      " 3:  4.9045e+01 -1.6025e+01  7e+01  2e-03  2e+01\n",
      " 4:  1.7912e+01 -4.8886e-01  2e+01  4e-04  6e+00\n",
      " 5:  9.1888e+00  3.6620e+00  6e+00  1e-04  2e+00\n",
      " 6:  7.0540e+00  4.7011e+00  2e+00  3e-05  4e-01\n",
      " 7:  6.1517e+00  5.1586e+00  1e+00  1e-05  1e-01\n",
      " 8:  5.8453e+00  5.3208e+00  5e-01  4e-06  5e-02\n",
      " 9:  5.6398e+00  5.4339e+00  2e-01  6e-07  9e-03\n",
      "10:  5.5724e+00  5.4809e+00  9e-02  2e-07  2e-03\n",
      "11:  5.5421e+00  5.5043e+00  4e-02  5e-08  8e-04\n",
      "12:  5.5272e+00  5.5161e+00  1e-02  6e-09  9e-05\n",
      "13:  5.5220e+00  5.5207e+00  1e-03  2e-10  3e-06\n",
      "14:  5.5214e+00  5.5213e+00  7e-05  9e-12  1e-07\n",
      "15:  5.5213e+00  5.5213e+00  4e-06  5e-13  7e-09\n",
      "Optimal solution found.\n",
      "75 0.9735294117647059\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  8.5324e+00  8.9920e+02  7e+04  3e+00  4e+04\n",
      " 1:  2.2780e+02 -1.1580e+03  1e+03  6e-02  7e+02\n",
      " 2:  1.6130e+02 -2.0991e+02  4e+02  1e-02  1e+02\n",
      " 3:  5.9444e+01 -1.9759e+01  8e+01  2e-03  2e+01\n",
      " 4:  2.2595e+01 -6.7843e-01  2e+01  6e-04  7e+00\n",
      " 5:  1.2971e+01  4.1423e+00  9e+00  2e-04  2e+00\n",
      " 6:  9.4723e+00  5.8854e+00  4e+00  6e-05  7e-01\n",
      " 7:  7.9320e+00  6.6420e+00  1e+00  1e-05  2e-01\n",
      " 8:  7.5056e+00  6.8700e+00  6e-01  5e-06  5e-02\n",
      " 9:  7.3034e+00  6.9833e+00  3e-01  1e-06  2e-02\n",
      "10:  7.1770e+00  7.0686e+00  1e-01  3e-07  4e-03\n",
      "11:  7.1340e+00  7.0980e+00  4e-02  3e-08  4e-04\n",
      "12:  7.1199e+00  7.1101e+00  1e-02  6e-09  7e-05\n",
      "13:  7.1160e+00  7.1136e+00  2e-03  1e-09  1e-05\n",
      "14:  7.1149e+00  7.1145e+00  4e-04  7e-11  8e-07\n",
      "15:  7.1147e+00  7.1147e+00  1e-05  2e-12  2e-08\n",
      "16:  7.1147e+00  7.1147e+00  1e-07  2e-14  2e-10\n",
      "Optimal solution found.\n",
      "100 0.9741176470588235\n"
     ]
    }
   ],
   "source": [
    "C_param = [1, 5, 10, 15, 20, 50, 75, 100]\n",
    "\n",
    "for i in C_param:\n",
    "    svm_model = svm_train_primal(data_train , label_train , i)\n",
    "    test_accuracy = svm_predict_primal(data_val , label_val, svm_model)\n",
    "    print(i, test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.0159e+00  6.8843e+02  7e+04  3e+00  4e+04\n",
      " 1:  2.3159e+01 -7.4260e+02  8e+02  4e-02  5e+02\n",
      " 2:  2.1449e+01 -5.9102e+01  8e+01  3e-03  4e+01\n",
      " 3:  1.2255e+01 -4.8566e+00  2e+01  4e-04  5e+00\n",
      " 4:  2.8854e+00  2.7904e-01  3e+00  4e-05  5e-01\n",
      " 5:  1.6190e+00  8.2015e-01  8e-01  1e-05  1e-01\n",
      " 6:  1.4284e+00  9.2156e-01  5e-01  5e-06  8e-02\n",
      " 7:  1.2900e+00  9.9213e-01  3e-01  2e-06  3e-02\n",
      " 8:  1.2058e+00  1.0372e+00  2e-01  1e-06  2e-02\n",
      " 9:  1.1498e+00  1.0686e+00  8e-02  4e-07  6e-03\n",
      "10:  1.1165e+00  1.0889e+00  3e-02  7e-08  1e-03\n",
      "11:  1.1043e+00  1.0977e+00  7e-03  1e-08  2e-04\n",
      "12:  1.1013e+00  1.1000e+00  1e-03  2e-09  2e-05\n",
      "13:  1.1007e+00  1.1005e+00  2e-04  2e-10  3e-06\n",
      "14:  1.1006e+00  1.1006e+00  9e-06  9e-12  1e-07\n",
      "15:  1.1006e+00  1.1006e+00  2e-07  2e-13  3e-09\n",
      "Optimal solution found.\n",
      "test_accuracy_train 0.9769117647058824\n",
      "test_accuracy_val 0.9770588235294118\n",
      "test_accuracy_test 0.9706666666666667\n"
     ]
    }
   ],
   "source": [
    "svm_model = svm_train_primal(data_train , label_train , 10)\n",
    "\n",
    "test_accuracy_train = svm_predict_primal(data_train , label_train , svm_model)\n",
    "print('test_accuracy_train', test_accuracy_train)\n",
    "\n",
    "test_accuracy_val = svm_predict_primal(data_val , label_val , svm_model)\n",
    "print('test_accuracy_val', test_accuracy_val)\n",
    "\n",
    "test_accuracy_test = svm_predict_primal(data_test , label_test , svm_model)\n",
    "print('test_accuracy_test', test_accuracy_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_prim = svm_model[:data_train.shape[1]]\n",
    "b_prim = svm_model[-1]\n",
    "primal_weights = pd.Series(w_prim)\n",
    "primal_b = pd.Series(b_prim)\n",
    "primal_series = pd.concat([primal_weights, primal_b], axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999 0.9741176470588235\n",
      "3.0 0.9764705882352941\n",
      "5.0 0.9758823529411764\n",
      "7.000000000000001 0.9758823529411764\n",
      "10.0 0.9770588235294118\n",
      "15.0 0.9752941176470589\n",
      "20.0 0.9752941176470589\n",
      "50.0 0.9729411764705882\n",
      "75.0 0.9735294117647059\n",
      "100.0 0.9741176470588235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "C_param = [1, 3, 5, 7, 10, 15, 20, 50, 75, 100]\n",
    "C_param = [element / data_train.shape[0] for element in C_param]\n",
    "\n",
    "for i in C_param:\n",
    "    clf = SVC(C = i, kernel = 'linear')\n",
    "    clf.fit(data_train, label_train) \n",
    "    y_ = clf.predict(data_val)\n",
    "    score = accuracy_score(label_val, y_)\n",
    "    print(i*data_train.shape[0], score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.9769117647058824\n",
      "test score 0.9706666666666667\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C = 10/data_train.shape[0], kernel = 'linear')\n",
    "clf.fit(data_train, label_train) \n",
    "\n",
    "y_pred_train = clf.predict(data_train)\n",
    "train_score = accuracy_score(label_train, y_pred_train)\n",
    "print('train score',train_score)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(data_test)\n",
    "test_score = accuracy_score(label_test, y_pred)\n",
    "print('test score',test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_w = clf.coef_\n",
    "SVM_b = clf.intercept_\n",
    "SVM_w_series = SVM_w.flatten()\n",
    "SVM_w_series = pd.Series(SVM_w_series)\n",
    "SVM_b_series = pd.Series(SVM_b)\n",
    "SVM_series = pd.concat((SVM_w_series, SVM_b_series), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dual</th>\n",
       "      <th>primal</th>\n",
       "      <th>D_P_dif</th>\n",
       "      <th>D_P_diff pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.002751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.023844</td>\n",
       "      <td>-0.023844</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.000417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.030614</td>\n",
       "      <td>0.030614</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.008669</td>\n",
       "      <td>-0.008669</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.002876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>0.028167</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.001835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>-0.021071</td>\n",
       "      <td>-0.021070</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.003592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.466676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>-0.007237</td>\n",
       "      <td>-0.007236</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.011780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>-0.000761</td>\n",
       "      <td>-0.000761</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.016109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.085559</td>\n",
       "      <td>1.142794</td>\n",
       "      <td>0.0572</td>\n",
       "      <td>5.272415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dual    primal  D_P_dif  D_P_diff pct\n",
       "0    0.003583  0.003583  -0.0000     -0.002751\n",
       "1   -0.023844 -0.023844  -0.0000      0.000417\n",
       "2    0.030614  0.030614  -0.0000     -0.000508\n",
       "3   -0.008669 -0.008669   0.0000     -0.002876\n",
       "4    0.028168  0.028167  -0.0000     -0.001835\n",
       "..        ...       ...      ...           ...\n",
       "196 -0.021071 -0.021070   0.0000     -0.003592\n",
       "197  0.000170  0.000171   0.0000      0.466676\n",
       "198 -0.007237 -0.007236   0.0000     -0.011780\n",
       "199 -0.000761 -0.000761  -0.0000      0.016109\n",
       "0    1.085559  1.142794   0.0572      5.272415\n",
       "\n",
       "[201 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weight and bias compare\n",
    "param_compare = pd.concat([dual_series.rename('dual'), primal_series.rename('primal')], axis=1)\n",
    "param_dif = round((param_compare['primal'] - param_compare['dual']),4)\n",
    "param_diff = (param_compare['primal'] - param_compare['dual'])/param_compare['dual']*100\n",
    "param_compare_1 = pd.concat([param_compare, param_dif.rename('D_P_dif'), param_diff.rename('D_P_diff pct')], axis=1)\n",
    "param_compare_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dual</th>\n",
       "      <th>primal</th>\n",
       "      <th>D_P_dif</th>\n",
       "      <th>D_P_diff pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-0.000931</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.054769</td>\n",
       "      <td>0.054769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-0.370321</td>\n",
       "      <td>-0.370321</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.186741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-0.010879</td>\n",
       "      <td>-0.010879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-0.000824</td>\n",
       "      <td>-0.000824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.001640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.421672</td>\n",
       "      <td>0.421672</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.466676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dual      primal  D_P_dif  D_P_diff pct\n",
       "count  200.000000  200.000000    200.0    200.000000\n",
       "mean    -0.000931   -0.000930      0.0      0.002686\n",
       "std      0.054769    0.054769      0.0      0.046644\n",
       "min     -0.370321   -0.370321     -0.0     -0.186741\n",
       "25%     -0.010879   -0.010879      0.0     -0.002131\n",
       "50%     -0.000824   -0.000824      0.0     -0.000562\n",
       "75%      0.010700    0.010700     -0.0      0.001640\n",
       "max      0.421672    0.421672     -0.0      0.466676"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only weights compare\n",
    "weights_compare_2 = param_compare_1.iloc[:200]\n",
    "weights_compare_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dual</th>\n",
       "      <th>primal</th>\n",
       "      <th>D_P_dif</th>\n",
       "      <th>D_P_diff pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.004475</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.028904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.094115</td>\n",
       "      <td>0.097430</td>\n",
       "      <td>0.004035</td>\n",
       "      <td>0.374599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-0.370321</td>\n",
       "      <td>-0.370321</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.186741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-0.010844</td>\n",
       "      <td>-0.010843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-0.000761</td>\n",
       "      <td>-0.000761</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.085559</td>\n",
       "      <td>1.142794</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>5.272415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dual      primal     D_P_dif  D_P_diff pct\n",
       "count  201.000000  201.000000  201.000000    201.000000\n",
       "mean     0.004475    0.004760    0.000285      0.028904\n",
       "std      0.094115    0.097430    0.004035      0.374599\n",
       "min     -0.370321   -0.370321   -0.000000     -0.186741\n",
       "25%     -0.010844   -0.010843    0.000000     -0.002120\n",
       "50%     -0.000761   -0.000761   -0.000000     -0.000527\n",
       "75%      0.011016    0.011016    0.000000      0.001666\n",
       "max      1.085559    1.142794    0.057200      5.272415"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_compare_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a1ce56f90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting w and b\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "x = range(0,201)\n",
    "plt.scatter(x, param_compare_1['primal'], alpha=1, label=\"primal\")\n",
    "plt.scatter(x, param_compare_1['dual'], alpha=1, marker = 'x', label=\"dual\" )\n",
    "plt.title('Weights and Bias Comparison', fontsize=20)\n",
    "plt.legend(loc='upper left', prop={'size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
